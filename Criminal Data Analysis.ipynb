{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will be  implementing different validation methods and compare their performances.\n",
    "Here, we are working with dataset about criminal records in various community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Lasso # For LASSO\n",
    "from sklearn.metrics import mean_squared_error # For evaluation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>agePct65up</th>\n",
       "      <th>...</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>nonViolPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11980</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.37</td>\n",
       "      <td>91.78</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.88</td>\n",
       "      <td>12.47</td>\n",
       "      <td>21.44</td>\n",
       "      <td>10.93</td>\n",
       "      <td>11.33</td>\n",
       "      <td>...</td>\n",
       "      <td>10.66</td>\n",
       "      <td>53.72</td>\n",
       "      <td>65.29</td>\n",
       "      <td>78.09</td>\n",
       "      <td>89.14</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1845.9</td>\n",
       "      <td>9.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1394.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23123</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>95.57</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.85</td>\n",
       "      <td>11.01</td>\n",
       "      <td>21.30</td>\n",
       "      <td>10.48</td>\n",
       "      <td>17.18</td>\n",
       "      <td>...</td>\n",
       "      <td>8.30</td>\n",
       "      <td>77.17</td>\n",
       "      <td>71.27</td>\n",
       "      <td>90.22</td>\n",
       "      <td>96.12</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2186.7</td>\n",
       "      <td>3.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29344</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>94.33</td>\n",
       "      <td>3.43</td>\n",
       "      <td>2.35</td>\n",
       "      <td>11.36</td>\n",
       "      <td>25.88</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.28</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>44.77</td>\n",
       "      <td>36.60</td>\n",
       "      <td>61.26</td>\n",
       "      <td>82.85</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2780.9</td>\n",
       "      <td>4.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6167.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11245</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>89.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.52</td>\n",
       "      <td>24.46</td>\n",
       "      <td>40.53</td>\n",
       "      <td>28.69</td>\n",
       "      <td>12.65</td>\n",
       "      <td>...</td>\n",
       "      <td>1.74</td>\n",
       "      <td>73.75</td>\n",
       "      <td>42.22</td>\n",
       "      <td>60.34</td>\n",
       "      <td>89.02</td>\n",
       "      <td>11.5</td>\n",
       "      <td>974.2</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9988.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140494</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.51</td>\n",
       "      <td>95.65</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.95</td>\n",
       "      <td>18.09</td>\n",
       "      <td>32.89</td>\n",
       "      <td>20.04</td>\n",
       "      <td>13.26</td>\n",
       "      <td>...</td>\n",
       "      <td>1.49</td>\n",
       "      <td>64.35</td>\n",
       "      <td>42.29</td>\n",
       "      <td>70.61</td>\n",
       "      <td>85.66</td>\n",
       "      <td>70.4</td>\n",
       "      <td>1995.7</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6867.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0       11980           3.10          1.37         91.78          6.50   \n",
       "1       23123           2.82          0.80         95.57          3.44   \n",
       "2       29344           2.43          0.74         94.33          3.43   \n",
       "3       11245           2.76          0.53         89.16          1.17   \n",
       "4      140494           2.45          2.51         95.65          0.90   \n",
       "\n",
       "   racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  ...  \\\n",
       "0         1.88        12.47        21.44        10.93       11.33  ...   \n",
       "1         0.85        11.01        21.30        10.48       17.18  ...   \n",
       "2         2.35        11.36        25.88        11.01       10.28  ...   \n",
       "3         0.52        24.46        40.53        28.69       12.65  ...   \n",
       "4         0.95        18.09        32.89        20.04       13.26  ...   \n",
       "\n",
       "   PctForeignBorn  PctBornSameState  PctSameHouse85  PctSameCity85  \\\n",
       "0           10.66             53.72           65.29          78.09   \n",
       "1            8.30             77.17           71.27          90.22   \n",
       "2            5.00             44.77           36.60          61.26   \n",
       "3            1.74             73.75           42.22          60.34   \n",
       "4            1.49             64.35           42.29          70.61   \n",
       "\n",
       "   PctSameState85  LandArea  PopDens  PctUsePubTrans  LemasPctOfficDrugUn  \\\n",
       "0           89.14       6.5   1845.9            9.63                  0.0   \n",
       "1           96.12      10.6   2186.7            3.84                  0.0   \n",
       "2           82.85      10.6   2780.9            4.37                  0.0   \n",
       "3           89.02      11.5    974.2            0.38                  0.0   \n",
       "4           85.66      70.4   1995.7            0.97                  0.0   \n",
       "\n",
       "   nonViolPerPop  \n",
       "0        1394.59  \n",
       "1        1955.95  \n",
       "2        6167.51  \n",
       "3        9988.79  \n",
       "4        6867.42  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the file\n",
    "data = pd.read_csv('community.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will observe the data now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2118, 102)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create our response and predictor variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the X and Y\n",
    "X = data.copy() \n",
    "del X['nonViolPerPop']\n",
    "y = data['nonViolPerPop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to track various computing process timings, we have defined tic and toe, which will basically be placed in our code's beginning and end respectively. Their time difference will be our computing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- Computation time = 0.0ms\n"
     ]
    }
   ],
   "source": [
    "#Computing process timing\n",
    "import time\n",
    "tic = time.process_time()   #stores process time\n",
    "toc = time.process_time()   #stores process time\n",
    "print (\"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now before the fitting the data we will split the data into training, test and validation data. Then we scale the data. We have placed tic at the top of code and toc at the bottom to calculate computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population            -0.004981\n",
      "householdsize          0.029821\n",
      "racepctblack           0.009925\n",
      "racePctWhite           0.006423\n",
      "racePctAsian           0.041576\n",
      "                         ...   \n",
      "PctSameState85        -0.047977\n",
      "LandArea              -0.020620\n",
      "PopDens                0.054011\n",
      "PctUsePubTrans         0.036836\n",
      "LemasPctOfficDrugUn    0.002286\n",
      "Length: 101, dtype: float64\n",
      "population             0.590395\n",
      "householdsize          1.022156\n",
      "racepctblack           1.048639\n",
      "racePctWhite           0.998521\n",
      "racePctAsian           1.070864\n",
      "                         ...   \n",
      "PctSameState85         1.052080\n",
      "LandArea               0.358184\n",
      "PopDens                1.229877\n",
      "PctUsePubTrans         1.007764\n",
      "LemasPctOfficDrugUn    1.273218\n",
      "Length: 101, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tic = time.process_time()\n",
    "# Train+Valid / test sets split. Use random_state 1\n",
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
    "\n",
    "# Train/valid sets split. Use random_state 1\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size = 0.3, random_state = 1)\n",
    "\n",
    "# Scale data (only fit with the training data, and transform both the training and validation data)\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X_train) \n",
    "X_valid = pd.DataFrame(scaler.transform(X_valid)) \n",
    "X_valid.columns = X.columns.values\n",
    "X_train = pd.DataFrame(scaler.transform(X_train)) \n",
    "X_train.columns = X.columns.values\n",
    "toc = time.process_time()\n",
    "print(X_valid.mean())\n",
    "print(X_valid.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ----- Computation time = 0.0ms\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can see that our computation time for scaling the data after splitting the data is 15.625ms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part, we will perform lasso regression on the data, print it's MSE values & coefficients and record it's computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       0           1\n",
      "0             population -214.971024\n",
      "1          householdsize -493.653070\n",
      "2           racepctblack  385.845159\n",
      "3           racePctWhite  411.795373\n",
      "4           racePctAsian  322.305410\n",
      "..                   ...         ...\n",
      "96        PctSameState85   68.394559\n",
      "97              LandArea  -68.425691\n",
      "98               PopDens -230.044354\n",
      "99        PctUsePubTrans -134.304970\n",
      "100  LemasPctOfficDrugUn  249.510874\n",
      "\n",
      "[101 rows x 2 columns]\n",
      "3317750.448686371\n"
     ]
    }
   ],
   "source": [
    "# Lasso regression\n",
    "tic = time.process_time()\n",
    "lm_lasso = linear_model.Lasso().fit(X_train,y_train)\n",
    "print(pd.DataFrame(zip(X_train.columns.values, lm_lasso.coef_)))\n",
    "print(metrics.mean_squared_error(lm_lasso.predict(X_valid), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Lasso Score is 0.5699344966981389\n",
      " ----- Computation time = 171.875ms\n"
     ]
    }
   ],
   "source": [
    "score=lm_lasso.score(X_valid, y_valid)\n",
    "toc = time.process_time()\n",
    "print (\" Lasso Score is \"+str(score)+\"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Lasso Score is 0.5699 and the computation time captured to perform this step is 1031.25 ms. This step is taking more time for computation maybe because it is considering all 101 predictors and then computing it's MSE value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will find best alpha parameter for the Lasso model and display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1e-10, 3328324.0690982915), (1e-09, 3328324.0690689855), (1e-08, 3328324.0687758923), (1e-07, 3328324.0658449708), (1e-06, 3328324.0365357804), (1e-05, 3328323.7434453345), (0.0001, 3328320.812686128), (0.001, 3328291.502464277), (0.01, 3327999.1876934455), (0.1, 3325361.8531911992), (1.0, 3317750.448686371), (10.0, 3351763.6297321427), (100.0, 3616281.0702169337), (1000.0, 5089594.534037838), (10000.0, 7714906.969245019), (100000.0, 7714906.969245019), (1000000.0, 7714906.969245019), (10000000.0, 7714906.969245019), (100000000.0, 7714906.969245019), (1000000000.0, 7714906.969245019), (10000000000.0, 7714906.969245019)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEWCAYAAABWn/G6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZhcVZ3/8fenO3vI0oEQknQgIIsoIktE1FFRFAIi4MygMM7PuA3K6KijjuI4I6iPPurM6MgoMi4IOC6ADkNGQYgoKo4sHXYEJGCa6iRkoStrd7bu7++PexoqTXW6qtO1pOrzep56+ta5597zrdud+ubce+65igjMzMyqpaXWAZiZWXNx4jEzs6py4jEzs6py4jEzs6py4jEzs6py4jEzs6py4jGzUSHpHyV9u9ZxWP2T7+OxZiNpOfDuiPhFrWMplOKaBfQBm4GfA++PiM21jMtstLnHY1Zf3hgR+wDHAMcCn6hEI5JaK7Ffs1I48Zglktok/VTSWkn5tNxesP7tkp6QtEnSnyS9NZUfKunXkjZIWifp6oJtXi7prrTuLkkvLyWWiHgKuIksAQ3sa7ykf5X0pKTVki6TNLFg/cckrZK0UtK7JYWkQ9O6KyR9Q9INkrYAr9nd/iTtlz7/ekndkn4rqSWt+7ikFek4PCrp5FR+saT/KojnTEkPpX3cKunIgnXLJX1U0v3p2FwtaUKZvzLbSznxmD2rBfgucBBwINALfA1A0mTgEuC0iJgCvBy4N233WeBmoA1oB/4jbTMD+Fnabl/gy8DPJO07XCAp4Z0GLCso/iJwOFkyOhSYC3wq1V8IfBh4XVr36iK7/Svgc8AU4Lbd7Q/4CNAFzCQ7/fePQEg6Ang/8JJ0HE4FlheJ/3Dgh8CH0j5uAP5X0riCam8GFgIHA0cDbx/uuFhjcOIxSyLi6Yj4SUT0RMQmsi/pwi/wfuAoSRMjYlVEPJTKd5AlqzkRsTUibkvlbwAei4jvRcTOiPgh8Ajwxt2E8T+SNgE5YA1wEYAkAX8D/H1EdKf4Pg+cm7Z7M/DdiHgoInqATxfZ9/UR8buI6Ae2DbO/HcBs4KCI2BERv43sgnAfMB54gaSxEbE8Ih4v0tZbgJ9FxJKI2AH8KzCRLGEPuCQiVkZEN/C/FPTurLE58ZglkiZJ+k9JnZI2Ar8BpktqjYgtZF+m7wVWSfqZpOenTT8GCLgznVp6ZyqfA3QOaqaTrGcxlLNTT+Ik4PnAfql8JjAJWJpOXa0nG3wws6CtXMF+CpeLlQ23v38h623dnE4vXggQEcvIejEXA2sk/UjSnCJt7fLZU7LLDfrsTxUs9wD7FNmPNSAnHrNnfQQ4AnhpREwFXpXKBRARN0XE68l6Ao8A30rlT0XE30TEHOA9wKXp2spKsp5QoQOBFcMFEhG/Bq4g6ykArCM79ffCiJieXtPSQASAVWSn+QbMK7bbguXd7i8iNkXERyLiELIe2ocHruVExA8i4s/SZwuyU3aD7fLZU49tXimf3RqfE481q7GSJhS8xpBd++gF1qfrMxcNVJY0K10sn0x2mmoz2WknJJ1TMAghT/Zl3Ed2XeNwSX8laYyktwAvAH5aYoz/Drxe0jGpx/At4CuS9k/tzpV0aqp7DfAOSUdKmsSz12qKGm5/ks5IgyYEbEyfp0/SEZJeK2k8sDUdr74iTVwDvEHSyZLGkiX1bcD/lfjZrYE58VizuoHsS3PgdTHZF/1Est7A7WSnnga0kH15rgS6ya79/G1a9xLgDkmbgcXAByPiTxHxNHBG2u5pslNyZ0TEulICjIi1wFXAP6eij5Od/ro9nQr8BVkPjYi4kWwQw69Snd+nbbbtpokh9wcclt5vTvu6NCJuJbu+84V0jJ4C9icbeDA49keBvyYbaLGOrNf0xojYXspnt8bmG0jNGlAauvwgMD4idtY6HrNC7vGYNQhJb5I0TlIb2XWX/3XSsXrkxGPWON4DrAUeJ7vuckFtwzErzqfazMysqtzjMTOzqhpT6wD2Bvvtt1/Mnz+/1mGYme1Vli5dui4iZg4ud+Ipwfz58+no6Kh1GGZmexVJg2fuAHyqzczMqsyJx8zMqsqJx8zMqsqJx8zMqsqJx8zMqsqJx8zMqsqJx8zMqsr38ZjZXmPF+l6u7cjR3++pvqrlzGPmcOj+U0Z1n048ZrbX+N7vO7ns148j1TqS5vHCudOceMyseT3ZvYVD9pvMLz96Uq1DsT3gazxmttfIdffSPmNSrcOwPeTEY2Z7jVy+h3ltE2sdhu0hJx4z2yts2rqD9T07mOcez17PicfM9gq57l4A5rU58eztnHjMbK+Qy/cAMG+GT7Xt7Zx4zGyvkOtOicc9nr2eE4+Z7RW68r3sM34M0yeNrXUotoeceMxsr5Dr7qG9bSLy3aN7PSceM9sr5PI9HtHWIJx4zKzuRQS57l5f32kQTjxmVvee3rKd3h19HtHWIJx4zKzueURbY3HiMbO6l8unm0d9jachOPGYWd0b6PG0e562huDEY2Z1ryvfw76TxzF5vJ/k0giceMys7vlxCI3FicfM6p4fh9BYnHjMrK719Qcr1/d6YEEDceIxs7r21Mat7OgLD6VuIE48ZlbXnrmHxzePNgwnHjOra755tPE48ZhZXcvle5FgznT3eBqFE4+Z1bWu7h5mT53AuDH+umoU/k2aWV3L5Xt8D0+DceIxs7rmxyE0HiceM6tb23b2sXrTVo9oazBOPGZWt1bke4nwiLZGU9HEI+kISfcWvDZK+pCkGZKWSHos/WxL9SXpEknLJN0v6biCfS1K9R+TtKig/HhJD6RtLlF6IPtI2jCz+uLHITSmiiaeiHg0Io6JiGOA44Ee4DrgQuCWiDgMuCW9BzgNOCy9zge+AVkSAS4CXgqcAFw0kEhSnfMLtluYystqw8zqj28ebUzVPNV2MvB4RHQCZwFXpvIrgbPT8lnAVZG5HZguaTZwKrAkIrojIg8sARamdVMj4vcREcBVg/ZVThtmVmdy+R7GtbYwa8qEWodio6iaiedc4IdpeVZErAJIP/dP5XOBXME2Xalsd+VdRcpH0sYuJJ0vqUNSx9q1a8v4mGY2Wrq6e5nbNpGWFtU6FBtFVUk8ksYBZwLXDle1SFmMoHwkbexaEPHNiFgQEQtmzpw5zC7NrBJy+R4/dbQBVavHcxpwd0SsTu9XD5zeSj/XpPIuYF7Bdu3AymHK24uUj6QNM6szue4eDyxoQNVKPOfx7Gk2gMXAwMi0RcD1BeVvSyPPTgQ2pNNkNwGnSGpLgwpOAW5K6zZJOjGNZnvboH2V04aZ1ZHN23aS79nhodQNqOIPMJc0CXg98J6C4i8A10h6F/AkcE4qvwE4HVhGNgLuHQAR0S3ps8Bdqd5nIqI7LV8AXAFMBG5Mr7LbMLP64hFtjaviiScieoB9B5U9TTbKbXDdAN43xH4uBy4vUt4BHFWkvOw2zKx++HEIjcszF5hZXfLNo43LicfM6lKuu4fJ41ppmzS21qHYKHPiMbO61JXPRrSlWbCsgTjxmFldynX30u7rOw3JicfM6k5EkMv3eERbg3LiMbO6071lOz3b+zyirUE58ZhZ3fGItsbmxGNmdcc3jzY2Jx4zqzu5vG8ebWROPGZWd3LdvcyYPI7J4ys+uYrVgBOPmdWdrnwP8/w4hIblxGNmdSfX3UO7BxY0LCceM6srff3BivW9vr7TwJx4zKyurN64lR194RFtDcyJx8zqih+H0PiceMysrvjm0cbnxGNmdSXX3YMEc6ZPqHUoViFOPGZWV3L5Hg6YOoHxY1prHYpViBOPmdWVrm6PaGt0TjxmVldy+R7aPaKtoTnxmFnd2Lazj6c2bnWPp8E58ZhZ3Vi5fisRHtHW6Jx4zKxuPHsPj0+1NTInHjOrG888DsE9nobmxGNmdSPX3cvYVjFrqu/haWROPGZWN3L5HuZOn0hri2odilWQE4+Z1Y2u7h6fZmsCTjxmVjdy+V7aPZS64TnxmFld2LJtJ91btvtxCE3AicfM6sIzI9rc42l4TjxmVhdy3X4cQrNw4jGzuuCbR5uHE4+Z1YVcvodJ41qZMXlcrUOxCnPiMbO6kOvuYV7bJCTfw9PonHjMrC7kuns9oq1JOPGYWc1FRPYcHo9oawoVTzySpkv6saRHJD0s6WWSZkhaIumx9LMt1ZWkSyQtk3S/pOMK9rMo1X9M0qKC8uMlPZC2uUSpnz6SNsysNrq3bKdne59HtDWJYROPpFZJN+1BG18Ffh4RzwdeDDwMXAjcEhGHAbek9wCnAYel1/nAN1IMM4CLgJcCJwAXDSSSVOf8gu0WpvKy2jCz2snl01Bqj2hrCsMmnojoA7ZLmlruztM2rwK+k/a1PSLWA2cBV6ZqVwJnp+WzgKsiczswXdJs4FRgSUR0R0QeWAIsTOumRsTvIyKAqwbtq5w2zKxGnhlK7R5PUxhTYr3NwH2Sbga2DBRGxIeH2e4QYC3wXUkvBpYCHwRmRcSqtI9VkvZP9ecCuYLtu1LZ7sq7ipQzgjZWFQYu6XyyHhEHHnjgMB/TzPaEn8PTXEpNPL9Ir5Hs/zjg7yLiDklf5dlTXsUUG0cZIyjfnZK2iYhvAt8EWLBgwXD7NLM9kOvupW3SWPYZX+pXku3NSvotR8R3JI0BDk1FyyJiZwmbdgFdEXFHev9jssSzWtLs1BOZDawpqD+vYPt2YGUqP2lQ+a2pvL1IfUbQhpnVSFfej0NoJiWNapP0SmAZ2bWay4E/SnrFcNtFxFNATtIRqehk4A/AYmBgZNoi4Pq0vBh4Wxp5diKwIZ0uuwk4RVJbGlRwCnBTWrdJ0olpNNvbBu2rnDbMrEYGbh615lBqv/YrwOkR8QcASUcC3wMWlLDt3wHflzQOeAJ4B1nCu0bSu4AngXNS3RuA08mSXE+qS0R0S/oscFeq95mI6E7LFwBXABOBG9ML4AvltGFmtdHXH6xY38upRx1Q61CsSkpNPOMGkg5ARDycEsmwIuJeiieok4vUDeB9Q+zncrLe1uDyDuCoIuVPl9uGmVXf6o1b2dEX7vE0kVITz92S/pOslwPwVuCeyoRkZs3EQ6mbT6mJ573AB4CPkY0K+w3wH5UKysyah28ebT7DJh5JrcB/RsQi4EuVD8nMmkmuuwcJ5jrxNI1SZy6YLWlsFeIxsyaTy/cwa8oExo9prXUoViWlnmp7AvitpOvZdeaCSyoSlZk1jS4/DqHplDo79Vqy+dEmATMLXmZmeySX9z08zabUazxjI2J3U92YmZVt284+ntq4lXaPaGsqpV7jeUkVYjGzJrNy/VYiPKKt2ZR6jeceSf8NXMuu13gWVyQqM2sKvoenOZWaeGaRJZzTC8qCbN4zM7MR8eMQmlOps1P/v0oHYmbNJ9fdy9hWccDUCbUOxapot9d4JP2wYPnzg9bd+NwtzMxKl8v3MGf6RFpbij0myxrVcIMLnl+wvHDQOk8la2Z7pMuPQ2hKwyWe3T1500/lNLM9ksv75tFmNNw1nkmSXkSWoCamZaWX/1rMbMS2bNtJ95bttLvH03SGSzxrgUvT8rqC5YH3ZmYj4hFtzWu3iSciXlnKTiS9NiJ+OTohmVkzyHVnj0M40Imn6ZQ6V9tw/nWU9mNmTeKZm0c9a0HTGa3E47GQZlaWXL6HSeNamTF5XK1DsSobrcTjEW5mVpZcdy/z2iYh+f+tzWa0Eo+ZWVm68j0eSt2kSko8kp4zCGFQWW7UIjKzhhcR5Lp7PJS6SZXa47lzd2URcdbohGNmzSDfs4Mt2/s8lLpJ7XY4taT9gdnsevMowFSyp5GamZXNI9qa23A3kL4BeCfQDnydZxPPJuCfKxiXmTUw3zza3Ia7gfS7wHclvTkirqlSTGbW4AZuHnXiaU6lXuPZX9JUAEmXSbpT0skVjMvMGlgu30PbpLHsM77UZ1FaIyk18ZwfERslnUJ22u0C4EuVC8vMGlmuu8e9nSZWauIZuEH0NOC7EbG0jG3NzHbRle/1c3iaWKnJ4z5JNwBvBG6UtA+ercDMRqC/P1iR76XdN482rVJPsL4DOB5YFhE9kvYD3lW5sMysUa3etJXtff3u8TSxkno8EdEHHEJ2bQeyh8D5VJuZlc0j2qzUKXO+BrwG+OtUtAW4rFJBmVnj8s2jVuqptpdHxHGS7gGIiG5JnsvczMqWy/cgwVwnnqZV6umyHZJaSAMKJO0L9FcsKjNrWLnuXmZNmcD4Ma21DsVqZLeJp2AG6q8DPwFmSvo0cBvwxQrHZmYN6LE1mzh4v8m1DsNqaLgez50AEXEV8E9kj7jOA+dExI9KaUDSckkPSLpXUkcqmyFpiaTH0s+2VC5Jl0haJul+SccV7GdRqv+YpEUF5cen/S9L22qkbZhZZfVs38lDKzdy3EHTax2K1dBwieeZRwNGxEMR8dWI+PeIeLDMdl4TEcdExIL0/kLglog4DLglvYfsBtXD0ut84BuQJRHgIuClwAnARQOJJNU5v2C7hSNpw8wq777cBvr6gwUHzah1KFZDww0umCnpw0OtjIgvj7Dds4CT0vKVwK3Ax1P5VRERwO2SpkuaneouiYhuAElLgIWSbgWmRsTvU/lVwNnAjeW2ERGrRvhZzKxESzu7ATj2QPd4mtlwPZ5WYB9gyhCvUgRws6Slks5PZbMGvujTz/1T+Vx2fZppVyrbXXlXkfKRtLELSedL6pDUsXbt2hI/qpntTkdnnsP234fpkzwotpkN1+NZFRGf2cM2XhERK9ND5ZZIemQ3dVWkLEZQvjslbRMR3wS+CbBgwQJPD2S2h/r7g7s787zh6Nm1DsVqrORrPCMVESvTzzXAdWTXaFanU2ikn2tS9S5gXsHm7cDKYcrbi5QzgjbMrIKWrd3Mxq07Od7Xd5recIlnj565I2mypCkDy8ApwIPAYmBgZNoi4Pq0vBh4Wxp5diKwIZ0muwk4RVJbGlRwCnBTWrdJ0olpNNvbBu2rnDbMrII6lucBWHBQ2zA1rdEN9wTS7j3c/yzgujTCeQzwg4j4uaS7gGskvQt4Ejgn1b8BOB1YBvSQTU46MFPCZ4G7Ur3PFMR2AXAF2fxxN6YXwBfKacPMKqujs5v99hnHQft6jrZmV9HH/0XEE8CLi5Q/TZHeVBpp9r4h9nU5cHmR8g7gqNFow8wqZ2lnnuMObCP9R9SamGeYNrOKW7tpG51P97Bgvk+zmROPmVXBwP07Hlhg4MRjZlWwtDPPuDEtHDV3aq1DsTrgxGNmFdfRmefF7dM8I7UBTjxmVmFbd/Tx4IoNPs1mz3DiMbOKur9rAzv6guN9/44lTjxmVlEdzwwscOKxjBOPmVXU0uV5Dpk5mRmTPTGoZZx4zKxiIoKlT+Y9TY7twonHzCrm8bVbWN+zww9+s1048ZhZxQzcOHqcezxWwInHzCqmY3metkljed7MybUOxeqIE4+ZVczSzjzHH+SJQW1XTjxmVhFPb97GE+u2+MZRew4nHjOriLufXA/gGantOZx4zKwiOjq7GdsqXjR3Wq1DsTrjxGNmFbF0eZ6j5k5jwlhPDGq7cuIxs1G3bWcf96/Y4BtHrSgnHjMbdQ+u2MD2nf0eWGBFOfGY2ajrWJ4HPDGoFefEY2ajbmlnnvn7TmLmlPG1DsXqkBOPmY2qiEg3jvo0mxXnxGNmo2r50z08vWW7T7PZkJx4zGxUdSzPJgb1jaM2FCceMxtVSzvzTJ0whkNn7lPrUKxOOfGY2ajqSBODtrR4YlArzonHzEbN+p7tLFuzmQXzPbDAhubEY2aj5u4nff+ODc+Jx8xGTcfyPGNaxIvbp9c6FKtjTjxmNmo6OvO8cM5UJo7zxKA2NCceMxsV23f2c19uvW8ctWE58ZjZqPjDqo1s29nv+3dsWE48ZjYqBm4c9cACG44Tj5mNiqWdedrbJjJr6oRah2J1zonHzPZYRNDRmfeD36wkTjxmtsdy3b2s3bSN433jqJWgKolHUqukeyT9NL0/WNIdkh6TdLWkcal8fHq/LK2fX7CPT6TyRyWdWlC+MJUtk3RhQXnZbZjZyHR0polB3eOxElSrx/NB4OGC918EvhIRhwF54F2p/F1APiIOBb6S6iHpBcC5wAuBhcClKZm1Al8HTgNeAJyX6pbdhpmN3NLOPFPGj+HwWVNqHYrtBSqeeCS1A28Avp3eC3gt8ONU5Urg7LR8VnpPWn9yqn8W8KOI2BYRfwKWASek17KIeCIitgM/As4aYRtmNkJLO/Mce1AbrZ4Y1EpQjR7PvwMfA/rT+32B9RGxM73vAuam5blADiCt35DqP1M+aJuhykfSxi4knS+pQ1LH2rVry//UZk1iQ+8OHl29ieMP9Gk2K01FE4+kM4A1EbG0sLhI1Rhm3WiVD9f+swUR34yIBRGxYObMmUU2MTOAe57ME+EHv1npxlR4/68AzpR0OjABmErWA5ouaUzqcbQDK1P9LmAe0CVpDDAN6C4oH1C4TbHydSNow8xGYGlnntYWccw8TwxqpalojyciPhER7RExn2xwwC8j4q3Ar4C/TNUWAden5cXpPWn9LyMiUvm5aUTawcBhwJ3AXcBhaQTbuNTG4rRNuW2Y2Qh0LM9z5OwpTB5f6f/HWqOo1X08Hwc+LGkZ2fWV76Ty7wD7pvIPAxcCRMRDwDXAH4CfA++LiL7Um3k/cBPZqLlrUt2y2zCz8u3s6+fe3HoWeGJQK0PV/osSEbcCt6blJ8hGpA2usxU4Z4jtPwd8rkj5DcANRcrLbsPMyvPwqk307ujz/GxWFs9cYGYjNnDjqBOPlcOJx8xGrKMzz5xpE5gzfWKtQ7G9iBOPmY1IRLB0ed7zs1nZnHjMbERWrO/lqY1bPT+blc2Jx8xGZGlnHvD1HSufE4+ZjcjSzjyTxrXy/AM8MaiVx4nHzEakY3meYw+czphWf41YefwXY2Zl27xtJ488tZHjfeOojYATj5mV7Z4n8/SHH/xmI+PEY2Zl61iep0Vw7IGeGNTK58RjZmW7+8k8RxwwlSkTxtY6FNsLOfGYWckigu/+7k/83+NPc+Ihvr5jI+N5zM2sJD3bd3LhTx5g8X0red2Rs/j71x9e65BsL+XEY2bD+tO6Lbz3e0t5bM0m/uHUI7jg1c+jpaXYw3zNhufEY2a7dfNDT/GRa+5jTKu48p0n8MrD/Ch42zNOPGZWVF9/8G83P8qltz7O0e3TuPStx9HeNqnWYVkDcOIxs+fo3rKdD/zwHm5bto7zTjiQi974AiaMba11WNYgnHjMbBf35tbzt/+1lHVbtvOlvziaN79kXq1DsgbjxGNmQDZU+od35rh48UPMnDKen7z35byofVqtw7IG5MRjZmzd0cenrn+Qazq6eNXhM/nqW46hbfK4WodlDcqJx6zJ5bp7uOD7S3lwxUY+8NpD+eDrDqfVQ6Wtgpx4zJrYrY+u4UNX30tff/CdRQs4+chZtQ7JmoATj1mTiAg2bdvJmo3bWLNxK797fB2X3vo4zz9gKpf99XEctO/kWodoTcKJp4IefWoTnU9vqXUYNkLSrqebBp98KlzdIiEV/5m9sv21FJQNrG9tEWNbxdjWlvQSY8e0MK61hTEt2frBsRSKCDZv28nqjdtYs2krazZuY/XGrazZlH6m8tUbt9G7o2+Xbf/82Ll87k0vYuI4D5W26nHiqaBrO3J8+7Y/1ToM28tJMLY1JaKUoAaWI2Dd5m30bO97znYTx7ZywLQJzJwynhe1T+d1U8Yza+oE9p86nv2nTGDO9Anu5VhNOPFU0LtfeQhnHzu31mHYKIgY9J7YZV0A/RFEBP0B/f1RUJb97I+COv3PlvX1Bzv7+9m+s58dfcGOvv70enZ5e18/Owvf78yWA5i5z3hmTd01qcyaOp59xo/ZbU/JrFaceCrogGkTOGDahFqHYWZWV/w8HjMzqyonHjMzqyonHjMzqyonHjMzqyonHjMzqyonHjMzqyonHjMzqyonHjMzqyrF4Fuy7TkkrQU6R7j5fsC6UQxntDiu8jiu8jiu8tVrbHsS10ERMXNwoRNPhUnqiIgFtY5jMMdVHsdVHsdVvnqNrRJx+VSbmZlVlROPmZlVlRNP5X2z1gEMwXGVx3GVx3GVr15jG/W4fI3HzMyqyj0eMzOrKiceMzOrKieeUSDpHEkPSeqXtGDQuk9IWibpUUmnDrH9wZLukPSYpKsljatAjFdLuje9lku6d4h6yyU9kOp1jHYcRdq7WNKKgthOH6LewnQMl0m6sApx/YukRyTdL+k6SdOHqFeV4zXc55c0Pv2Ol6W/pfmViqWgzXmSfiXp4fT3/8EidU6StKHg9/upSseV2t3t70WZS9Lxul/ScVWI6YiC43CvpI2SPjSoTtWOl6TLJa2R9GBB2QxJS9J30RJJbUNsuyjVeUzSorIbj/QoXr9G/gKOBI4AbgUWFJS/ALgPGA8cDDwOtBbZ/hrg3LR8GXBBheP9N+BTQ6xbDuxXxWN3MfDRYeq0pmN3CDAuHdMXVDiuU4AxafmLwBdrdbxK+fzA3wKXpeVzgaur8LubDRyXlqcAfywS10nAT6v191Tq7wU4HbgREHAicEeV42sFniK7wbImxwt4FXAc8GBB2ZeAC9PyhcX+7oEZwBPpZ1tabiunbfd4RkFEPBwRjxZZdRbwo4jYFhF/ApYBJxRWkCTgtcCPU9GVwNmVijW192bgh5VqowJOAJZFxBMRsR34EdmxrZiIuDkidqa3twPtlWxvGKV8/rPI/nYg+1s6Of2uKyYiVkXE3Wl5E/AwMLeSbY6is4CrInM7MF3S7Cq2fzLweESMdEaUPRYRvwG6BxUX/h0N9V10KrAkIrojIg8sARaW07YTT2XNBXIF77t47j/MfYH1BV9yxeqMplcCqyPisSHWB3CzpKWSzq9gHIXen053XD5E176U41hJ7yT733Ex1ThepXz+Z+qkv6UNZH9bVZFO7R0L3FFk9csk3SfpRkkvrFJIw/1eav03dS5D/+evFsdrwKyIWAXZfyyA/YvU2eNjN2bE4TUZSb8ADiiy6pMRcf1QmxUpGzx+vZQ6JSkxxvPYfW/nFRGxUtL+wBJJj6T/GY3Y7uICvgF8luwzf5bsNOA7B++iyLZ7fB9AKbNq/F0AAAavSURBVMdL0ieBncD3h9jNqB+vYqEWKavY31G5JO0D/AT4UERsHLT6brLTSZvT9bv/AQ6rQljD/V5qebzGAWcCnyiyulbHqxx7fOyceEoUEa8bwWZdwLyC9+3AykF11pF188ek/6kWqzMqMUoaA/w5cPxu9rEy/Vwj6Tqy0zx79EVa6rGT9C3gp0VWlXIcRz2udNH0DODkSCe3i+xj1I9XEaV8/oE6Xen3PI3nnkYZdZLGkiWd70fEfw9eX5iIIuIGSZdK2i8iKjoZZgm/l4r8TZXoNODuiFg9eEWtjleB1ZJmR8SqdOpxTZE6XWTXoga0k13fLplPtVXWYuDcNOLoYLL/udxZWCF9of0K+MtUtAgYqge1p14HPBIRXcVWSposacrAMtkF9geL1R0tg86rv2mI9u4CDlM2+m8c2WmKxRWOayHwceDMiOgZok61jlcpn38x2d8OZH9LvxwqWY6WdA3pO8DDEfHlIeocMHCtSdIJZN85T1c4rlJ+L4uBt6XRbScCGwZOMVXBkGcdanG8Bin8Oxrqu+gm4BRJbenU+CmprHTVGD3R6C+yL8wuYBuwGripYN0nyUYkPQqcVlB+AzAnLR9ClpCWAdcC4ysU5xXAeweVzQFuKIjjvvR6iOyUU6WP3feAB4D70x/97MFxpfenk42aerxKcS0jO499b3pdNjiuah6vYp8f+AxZYgSYkP52lqW/pUOqcIz+jOwUy/0Fx+l04L0Df2fA+9OxuY9skMbLqxBX0d/LoLgEfD0dzwcoGI1a4dgmkSWSaQVlNTleZMlvFbAjfX+9i+y64C3AY+nnjFR3AfDtgm3fmf7WlgHvKLdtT5ljZmZV5VNtZmZWVU48ZmZWVU48ZmZWVU48ZmZWVU48ZmZWVU481vQkbR6l/cyW9NNBZV9VNvt2S0HZ2yV9bZh9DVtniO3Ok/TJkW4/zL5PGvz5hqhXyuc7Q9KnRy8625s48ZiNng8D3xp4k5LNm8juB3pVlWJYCPy8Sm3tiZ8BZ0qaVOtArPqceMyKkHSQpFvS5KW3SDowlT9P0u2S7pL0mUG9pb9g1y/915DdMf8NsrvVi7VzhaTLJP1W0h8lnVGweo6knyt75smXCrb5hqQOZc/A+XRBuYBjyOb7GupzDbXtckmfl/T7tP44STdJelzSewt2MVXZ84n+kOJuSdu/I8X/a+AVBft9o7LnA90j6ReSZsEzM3bcSjYlkTUZJx6z4r5GNm3+0WQThF6Syr8KfDUiXkLB3F5pSqR8RGwr2MfA1CjXAWekec2KmQ+8GngDcJmkCan8GOAtwIuAt0gamFvskxGxADgaeLWko1P5scB9sfu7wofaFiAXES8Dfks2y8Vfkj2r5jMFdU4APpJieh7w52nao0+TJZzXkz2HasBtwIkRcSzZ4xw+VrCug2y2dGsyTjxmxb0M+EFa/h7Z9DAD5dem5R8U1J8NrB14k+ZUOx34n8gmfryDbE6rYq6JiP7IHlXxBPD8VH5LRGyIiK3AH4CDUvmbJd0N3AO8kGe/6Bcy9OMbBgy1LTw7/9sDZA9G2xQRa4GtevYJrHdG9lygPrKk+mfAS4FbI2JtZM8Lurpgn+3ATZIeAP4htTlgDdkURNZknHjMSjPc3FK9ZPOlDVhINkP0A5KWk31BFz3dVmTfA+8Le099wJjUs/oo2YzZR5NdKxlo9xTg5qECHGbbwvb6B7Xdz7Mz2Q8V61DH5z+Ar0XEi4D3DGpvAtlxsybjxGNW3P+RzQIN8FayU0aQTdz4F2n53IL6fyQ7ZTbgPODdETE/IuaTPfr8lCEupp8jqUXS88gmuCz2NNsBU4EtwIZ0veQ0AEnTyB7VvbuZjItuW6YT0izZLWSnAW8j682dJGnfdDrxnIL604AVaXnRrrvicCo8+7nVJz+PxwwmSSp8VMSXgQ8Al0v6B7JTaO9I6z4E/Jekj5D1GDYARMSWdCH+ULJrP6eS/Q+fgvW3AW8s0v6jwK+BWWSzFG/VEE+tjoj7JN1DNoPxE8Dv0qrXA78YVP3tkgofXXwi2Sm2wduW4/fAF8iu8fwGuC4i+iVdnNatIhvc0JrqXwxcK2kFWdI+uGBfr6H4w9CswXl2arMypB5Lb0SEpHOB8yLirLTuTcDxEfFPZezvCuCnEfHjPYzr22TT1t++J/upltTj+kFEnFzrWKz63OMxK8/xwNfS0OX1FDymOyKuk7RvLYKKiHfXot09cCDZ6DhrQu7xmJlZVXlwgZmZVZUTj5mZVZUTj5mZVZUTj5mZVZUTj5mZVdX/B+qwb5EkS8IVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "alphas = np.logspace(-10, 10, 21) # We will use lambda on powers of 10 scale\n",
    "alphas_index = np.linspace(-10, 10, 21) # The lambda values on log scale\n",
    "\n",
    "Validation_Scores = []\n",
    "for a in alphas:\n",
    "    lm = linear_model.Lasso(alpha=a)\n",
    "    lm.fit(X_train, y_train) # Fit model on training+validation set\n",
    "    Validation_Scores.append(metrics.mean_squared_error(lm.predict(X_valid), y_valid)) # Evaluate model on test set\n",
    "\n",
    "\n",
    "print(list(zip(alphas, Validation_Scores))) #print all alphas and validation scores to plot graph.\n",
    "plt.plot(alphas_index, Validation_Scores)\n",
    "plt.xlabel(\"Log(Alpha/Lambda)\")\n",
    "plt.ylabel(\"Test_Error\")\n",
    "plt.title(\"Lasso Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(Validation_Scores) #fetches minimum validation score.\n",
    "alphas[np.argmin(Validation_Scores)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will find the smallest prediction error for lasso model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       0           1\n",
      "0             population   -0.000000\n",
      "1          householdsize -303.932580\n",
      "2           racepctblack   49.602928\n",
      "3           racePctWhite    0.000000\n",
      "4           racePctAsian   43.385785\n",
      "..                   ...         ...\n",
      "96        PctSameState85   -0.000000\n",
      "97              LandArea  -28.751322\n",
      "98               PopDens -257.382070\n",
      "99        PctUsePubTrans  -95.741881\n",
      "100  LemasPctOfficDrugUn  244.265297\n",
      "\n",
      "[101 rows x 2 columns]\n",
      "3351763.6297321427\n",
      "\n",
      " ----- Computation time = 187.5ms\n"
     ]
    }
   ],
   "source": [
    "# Smallest Prediction Error\n",
    "tic = time.process_time()\n",
    "lm_lasso = linear_model.Lasso(alpha = 10).fit(X_train,y_train)\n",
    "toc = time.process_time()\n",
    "print(pd.DataFrame(zip(X_train.columns.values, lm_lasso.coef_)))\n",
    "print(metrics.mean_squared_error(lm_lasso.predict(X_valid), y_valid))\n",
    "print (\"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction error for testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population             1.460820e-17\n",
      "householdsize         -3.602606e-16\n",
      "racepctblack          -7.221694e-17\n",
      "racePctWhite           1.517754e-16\n",
      "racePctAsian           6.083003e-17\n",
      "                           ...     \n",
      "PctSameState85         3.456524e-16\n",
      "LandArea              -2.775558e-17\n",
      "PopDens               -5.184037e-17\n",
      "PctUsePubTrans        -2.458110e-18\n",
      "LemasPctOfficDrugUn   -7.164010e-16\n",
      "Length: 101, dtype: float64\n",
      "population             1.000338\n",
      "householdsize          1.000338\n",
      "racepctblack           1.000338\n",
      "racePctWhite           1.000338\n",
      "racePctAsian           1.000338\n",
      "                         ...   \n",
      "PctSameState85         1.000338\n",
      "LandArea               1.000338\n",
      "PopDens                1.000338\n",
      "PctUsePubTrans         1.000338\n",
      "LemasPctOfficDrugUn    1.000338\n",
      "Length: 101, dtype: float64\n",
      "              0                    1\n",
      "0      0.000000           population\n",
      "1   -477.290736        householdsize\n",
      "2    457.146689         racepctblack\n",
      "3    390.474557         racePctWhite\n",
      "4    252.671790         racePctAsian\n",
      "..          ...                  ...\n",
      "96     6.786263       PctSameState85\n",
      "97   -59.666816             LandArea\n",
      "98  -255.944269              PopDens\n",
      "99  -134.575891       PctUsePubTrans\n",
      "100  151.120050  LemasPctOfficDrugUn\n",
      "\n",
      "[101 rows x 2 columns]\n",
      "The prediction error on the testing set is 3622527.9572477085\n"
     ]
    }
   ],
   "source": [
    "#Now use the training+validation set, refit the model using the best lambda from above, and perform prediction on the test set. \n",
    "#At this point you should scale using both the training+validation data together. \n",
    "#What is the prediction error on the test set with this lambda value?\n",
    "\n",
    "\n",
    "# Scale data (use t\n",
    "scaler.fit(X_train_valid) \n",
    "X_train_valid = pd.DataFrame(scaler.transform(X_train_valid)) \n",
    "X_test = pd.DataFrame(scaler.transform(X_test)) \n",
    "X_train_valid.columns = X.columns.values\n",
    "X_test.columns = X.columns.values\n",
    "print(X_train_valid.mean())\n",
    "print(X_train_valid.std())\n",
    "\n",
    "\n",
    "# Refit model with train + validation set, perform prediction on test set\n",
    "lm = linear_model.Lasso(alpha = alphas[np.argmin(Validation_Scores)] )\n",
    "lm.fit(X_train_valid, y_train_valid)\n",
    "print(pd.DataFrame(zip(lm.coef_,X.columns)))\n",
    "print(\"The prediction error on the testing set is\", metrics.mean_squared_error(lm.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the values for:\n",
    "\n",
    "The prediction error on the validation set is 3351763.6297321427\n",
    "\n",
    "The prediction error on the testing set is 3622527.9572477085\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6268724646590897"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(X_valid, y_valid)  #accuracy of Lasso model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will be performing 5 fold cross validation and then 10 fold to compare their computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model pipeline\n",
    "estimator = Pipeline(steps = [('scale', StandardScaler()), # We first need to scale the data\n",
    "                     ('lasso', Lasso()) ]) # Then fit the scaled data using Lasso\n",
    "\n",
    "# Set up the parameters for each item in the pipeline\n",
    "# Parameters of pipelines can be set using â€˜__â€™ separating the parameter names:\n",
    "parameters = {'lasso__alpha': np.logspace(-10,10,21),\n",
    "             'lasso__max_iter': [50,70,100]} # Here is a second argument for Lasso, just to illustrate how to add\n",
    "                                          # multiple hyperparameters to tune. (have taken random num here)\n",
    "\n",
    "#Method-Grid Search-5 fold CV\n",
    "tic = time.process_time()\n",
    "reg = GridSearchCV(estimator = estimator, param_grid = parameters, cv = 5, \n",
    "                   scoring = 'neg_mean_squared_error', n_jobs = -1) # Instantiate the gridsearch\n",
    "reg.fit(X_train, y_train) # Fit the grid search, i.e. perform CV and grid search. \n",
    "reg.best_params_ # The best parameter from CV\n",
    "toc = time.process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.predict(X_test) # This is how we perform prediction\n",
    "mse=mean_squared_error(reg.predict(X_test), y_test)\n",
    "score=reg.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Parameters for 5 fold CV= {'lasso__alpha': 10.0, 'lasso__max_iter': 100}\n",
      " Mean Squared Error= 3538489.301508037\n",
      " Score= -3362366.7466791393\n",
      " ----- Computation time = 1546.875ms\n"
     ]
    }
   ],
   "source": [
    "print (\" Best Parameters for 5 fold CV= \" + str(reg.best_params_) + \"\\n Mean Squared Error= \" + str(mse)+\"\\n Score= \" + str(score)+\"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method-Grid Search-10 fold CV\n",
    "tic = time.process_time()\n",
    "reg = GridSearchCV(estimator = estimator, param_grid = parameters, cv = 10, \n",
    "                   scoring = 'neg_mean_squared_error', n_jobs = -1) # Instantiate the gridsearch\n",
    "reg.fit(X_train, y_train) # Fit the grid search, i.e. perform CV and grid search. \n",
    "reg.best_params_ # The best parameter from CV\n",
    "toc = time.process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.predict(X_test) # This is how we perform prediction\n",
    "mse=mean_squared_error(reg.predict(X_test), y_test)\n",
    "score=reg.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Parameters for 10 fold CV= {'lasso__alpha': 10.0, 'lasso__max_iter': 100}\n",
      " Mean Squared Error= 3538489.301508037\n",
      " Score= -3362366.7466791393\n",
      " ----- Computation time = 2718.75ms\n"
     ]
    }
   ],
   "source": [
    "print (\" Best Parameters for 10 fold CV= \" + str(reg.best_params_) + \"\\n Mean Squared Error= \" + str(mse)+\"\\n Score= \" + str(score)+\"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By performing the 5-fold CV & 10-fold CV, now we can compare both of them to observe that:\n",
    "\n",
    "    MSE for 5-fold is      3538489.301508037\n",
    "    MSE for 10-fold is     3538489.301508037\n",
    "    MSE for testing set is 3622527.9572477085\n",
    "\n",
    "    Score for 5-fold is      -3362366.7466791393\n",
    "    Score for 10-fold is     -3362366.7466791393\n",
    "    Score for testing set is  0.6268724646590897\n",
    "    \n",
    "    Computation time for 5-fold      is 1687.5 ms\n",
    "    Computation time for 10-fold     is 2484.375 ms\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data above, it can be observed that, the 5-fold CV is better than other methods as it has less computation time despite having similar MSE.\n",
    "Since, the number of records is limited, we don't see difference in the scores.Only the computation time is informing about the efficiency of the model. Hence, we will go with 5-fold CV with this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
